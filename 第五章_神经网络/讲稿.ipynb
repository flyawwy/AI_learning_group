{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. **引言**\n",
    "神经网络是模拟生物神经系统的计算模型，由大量简单的神经元相互连接而成。本章将重点介绍神经元模型、激活函数以及感知机的基本原理。\n",
    "\n",
    "#### 2. **神经元模型**\n",
    "- **M-P神经元模型**：1943年由McCulloch和Pitts提出，是神经网络的基础单元。神经元接收来自其他神经元的输入信号，通过带权重的连接传递，总输入值与阈值比较后，通过激活函数处理产生输出。\n",
    "  - **输入信号**：来自其他神经元的信号，权重表示连接强度。\n",
    "  - **阈值**：决定神经元是否被激活的临界值。\n",
    "  - **激活函数**：将输入映射为输出的函数，如阶跃函数或Sigmoid函数。\n",
    "\n",
    "![M-P神经元模型](https://lf26-appstore-sign.oceancloudapi.com/ocean-cloud-tos/BYTE_RAG_UPLOAD_BIZ_TYPE/None_1743418407908_J4FS6s5sfI.jpeg?lk3s=61a3dea3&x-expires=1746868828&x-signature=zFDsHTkfsceC7uRVXcZlUDimJCs%3D)\n",
    "\n",
    "#### 3. **激活函数**\n",
    "- **阶跃函数**：理想中的激活函数，输出为0或1，但因其不连续、不光滑，实际使用较少。\n",
    "- **Sigmoid函数**：典型的激活函数，将输入值压缩到(0,1)范围内，具有连续性和可微性，适合梯度下降优化。\n",
    "\n",
    "![典型的神经元激活函数](https://lf3-appstore-sign.oceancloudapi.com/ocean-cloud-tos/BYTE_RAG_UPLOAD_BIZ_TYPE/None_1743418407908_0H6YJR0V0R.jpeg?lk3s=61a3dea3&x-expires=1746868828&x-signature=QVP3UtW1dj9lpk4ZIS5JrX3VNAg%3D)\n",
    "\n",
    "#### 4. **感知机与多层网络**\n",
    "- **感知机**：由输入层和输出层组成，输出层为M-P神经元。通过调整权重和阈值，可以实现逻辑运算（如与、或、非）。\n",
    "- **多层网络**：将多个神经元按层次连接，形成更复杂的模型，如多层感知机（MLP）。\n",
    "\n",
    "![感知机与多层网络](https://lf9-appstore-sign.oceancloudapi.com/ocean-cloud-tos/BYTE_RAG_UPLOAD_BIZ_TYPE/None_1743418407908_0Z0t0ZFr63.jpeg?lk3s=61a3dea3&x-expires=1746868828&x-signature=yEmWQOZGQJcr4Z%2BCinT2xUoR6BA%3D)\n",
    "\n",
    "#### 5. **代码实例演示**\n",
    "以下是一个简单的神经网络训练实例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False     # 用来正常显示负号\n",
    "\n",
    "# 生成数据\n",
    "X = torch.linspace(-5, 5, 100).reshape(-1, 1)\n",
    "y = torch.sin(X) + 0.2 * torch.randn(X.size())\n",
    "\n",
    "# 定义网络\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 10)  # 输入层→隐藏层\n",
    "        self.fc2 = nn.Linear(10, 1)  # 隐藏层→输出层\n",
    "        self.activation = nn.ReLU()   # 激活函数\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 训练\n",
    "model = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "losses = []\n",
    "epochs = 1000\n",
    "\n",
    "# 创建一个图形，包含两个子图\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # 每100个epoch绘制一次预测结果\n",
    "    if epoch % 100 == 0 or epoch == epochs-1:\n",
    "        plt.clf()  # 清除当前图形\n",
    "        \n",
    "        # 绘制损失函数\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(losses, 'b-', label='训练损失')\n",
    "        plt.title('训练过程中的损失变化')\n",
    "        plt.xlabel('训练轮次')\n",
    "        plt.ylabel('损失值')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # 绘制预测结果\n",
    "        plt.subplot(1, 2, 2)\n",
    "        with torch.no_grad():\n",
    "            predicted = model(X)\n",
    "        plt.scatter(X.numpy(), y.numpy(), c='b', label='真实数据', alpha=0.5)\n",
    "        plt.plot(X.numpy(), predicted.numpy(), 'r-', label='模型预测', linewidth=2)\n",
    "        plt.title(f'预测结果 (Epoch {epoch+1})')\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.pause(0.5)  # 暂停一小段时间以显示动画效果\n",
    "\n",
    "plt.show()  # 显示最终结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. **总结**\n",
    "- 神经元模型是神经网络的基础，激活函数决定了神经元的输出特性。\n",
    "- 感知机是简单的神经网络，多层网络可以解决更复杂的问题。\n",
    "- 通过代码实例，可以直观理解神经网络的训练过程。\n",
    "\n",
    "---\n",
    "\n",
    "### 重难点讲解\n",
    "1. **神经元模型**：重点理解输入、权重、阈值和激活函数的作用。\n",
    "2. **激活函数**：Sigmoid函数的特性及其在梯度下降中的作用。\n",
    "3. **感知机**：如何通过调整参数实现逻辑运算。\n",
    "4. **代码实例**：演示神经网络的构建、训练和预测过程。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
